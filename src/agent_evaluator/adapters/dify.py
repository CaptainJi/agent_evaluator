"""Difyå¹³å°é€‚é…å™¨"""

import asyncio
import json
import time
from typing import Any

from agent_evaluator.adapters.base import AdapterResponse, PerformanceMetrics, PlatformAdapter
from agent_evaluator.adapters.streaming import StreamingAccumulator
from agent_evaluator.utils.logger import get_logger

logger = get_logger(__name__)

# Chat APIçš„ä¸Šä¸‹æ–‡å­—æ®µåï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼‰
CHAT_API_CONTEXT_FIELD = "retriever_resources"

# Workflow APIçš„ä¸Šä¸‹æ–‡å­—æ®µå¯èƒ½åç§°ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
WORKFLOW_API_CONTEXT_FIELDS = ["retrieved_contexts", "contexts", "context", "retrieved_context"]


class DifyAdapter(PlatformAdapter):
    """Difyå¹³å°é€‚é…å™¨"""

    def __init__(self, api_config: dict[str, Any], show_streaming_content: bool = False):
        """
        åˆå§‹åŒ–Difyé€‚é…å™¨
        
        Args:
            api_config: APIé…ç½®å­—å…¸
            show_streaming_content: æ˜¯å¦æ˜¾ç¤ºæµå¼è¾“å‡ºçš„è¯¦ç»†å†…å®¹
        """
        super().__init__(api_config)
        self.show_streaming_content = show_streaming_content

    def _get_headers(self) -> dict[str, str]:
        """è·å–Dify APIè¯·æ±‚å¤´"""
        headers = super()._get_headers()
        api_key = self.api_config.get("api_key")
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"
        return headers

    def _build_payload(self, input: str, response_mode: str, **kwargs: Any) -> dict[str, Any]:
        """æ„å»ºè¯·æ±‚payload - æ¶ˆé™¤é‡å¤ä»£ç """
        inputs = kwargs.get("inputs", {})
        query = inputs.get("query") if "query" in inputs else input
        # å¦‚æœqueryæ¥è‡ªinputsï¼Œpayloadä¸­çš„queryç”¨å ä½ç¬¦
        payload_query = "-" if "query" in inputs else query
        
        return {
            "inputs": inputs,
            "query": payload_query,
            "response_mode": response_mode,
            "conversation_id": kwargs.get("conversation_id"),
            "user": kwargs.get("user", "agent-evaluator"),
        }

    async def invoke(
        self,
        input: str,
        stream: bool = False,
        **kwargs: Any,
    ) -> AdapterResponse:
        """
        è°ƒç”¨Dify API

        Args:
            input: ç”¨æˆ·è¾“å…¥ï¼ˆå¦‚æœinputsä¸­åŒ…å«queryï¼Œåˆ™æ­¤å‚æ•°å¯èƒ½è¢«å¿½ç•¥ï¼‰
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            **kwargs: å…¶ä»–å‚æ•°ï¼ŒåŒ…æ‹¬ï¼š
                - conversation_id: å¯¹è¯IDï¼ˆå¯é€‰ï¼‰
                - user: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
                - app_id: åº”ç”¨IDï¼ˆå¯é€‰ï¼ŒæŸäº›APIå¯èƒ½éœ€è¦ï¼‰
                - inputs: å·¥ä½œæµè¾“å…¥å˜é‡å­—å…¸ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœåŒ…å«queryå­—æ®µï¼Œåˆ™ä½¿ç”¨inputs.queryä½œä¸ºå®é™…æŸ¥è¯¢

        Returns:
            AdapterResponseå¯¹è±¡
        """
        logger.debug(f"è°ƒç”¨Dify APIï¼Œæµå¼æ¨¡å¼: {stream}, è¾“å…¥é•¿åº¦: {len(input)}")
        method = self._invoke_streaming if stream else self._invoke_non_streaming
        return await method(input, **kwargs)

    async def _invoke_non_streaming(
        self,
        input: str,
        **kwargs: Any,
    ) -> AdapterResponse:
        """éæµå¼è°ƒç”¨"""
        if not self._client:
            raise RuntimeError("Adapter must be used as async context manager")

        base_url = self.api_config.get("base_url", "https://api.dify.ai/v1")
        path = kwargs.get("path", "chat-messages")
        url = f"{base_url}/{path}"
        payload = self._build_payload(input, "blocking", **kwargs)

        logger.debug(f"å‘é€éæµå¼è¯·æ±‚åˆ°: {url}")
        start_time = time.time()
        response = await self._client.post(url, json=payload)
        response.raise_for_status()

        response_data = response.json()
        total_time = time.time() - start_time
        logger.debug(f"APIè°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {total_time:.3f}ç§’")
        
        is_workflow = self._is_workflow_api(path)
        if is_workflow:
            # Workflow APIå“åº”ç»“æ„: {workflow_run_id, task_id, data: {...}}
            workflow_data = response_data.get("data", {})
            self._log_response_diagnostics(workflow_data, path)
            
            # Workflow APIæ²¡æœ‰answerå­—æ®µï¼Œç­”æ¡ˆåœ¨outputsä¸­
            outputs = workflow_data.get("outputs", {})
            answer = self._extract_answer_from_workflow_outputs(outputs)
            contexts = self._extract_contexts_from_workflow_outputs(outputs)
            
            metadata = {
                "workflow_run_id": response_data.get("workflow_run_id"),
                "task_id": response_data.get("task_id"),
                "workflow_id": workflow_data.get("workflow_id"),
                "status": workflow_data.get("status"),
                "created_at": workflow_data.get("created_at"),
                "finished_at": workflow_data.get("finished_at"),
                **response_data,
            }
            
            performance = self._extract_performance_metrics_from_workflow(workflow_data, total_time)
        else:
            # Chat APIå“åº”ç»“æ„: {answer, retriever_resources, ...}
            self._log_response_diagnostics(response_data, path)
            
            answer = response_data.get("answer", "")
            contexts = self._extract_contexts_from_chat_response(response_data)
            
            metadata = {
                "message_id": response_data.get("message_id"),
                "conversation_id": response_data.get("conversation_id"),
                "created_at": response_data.get("created_at"),
                **response_data,
            }
            
            performance = self._extract_performance_metrics_from_chat(response_data, total_time)
        
        return AdapterResponse(
            answer=answer,
            contexts=contexts,
            metadata=metadata,
            performance=performance,
        )

    def _is_workflow_api(self, path: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºWorkflow APIè·¯å¾„"""
        return "workflow" in path.lower() or path.endswith("/workflows/run")

    def _extract_answer_from_workflow_outputs(self, outputs: dict[str, Any]) -> str:
        """ä»Workflow APIçš„outputsä¸­æå–ç­”æ¡ˆ"""
        if not isinstance(outputs, dict):
            return ""
        
        # å°è¯•å¸¸è§çš„ç­”æ¡ˆå­—æ®µ
        for key in ["text", "answer", "output", "result", "content"]:
            if key in outputs:
                value = outputs[key]
                if isinstance(value, str):
                    return value
                elif isinstance(value, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–textæˆ–content
                    return str(value.get("text") or value.get("content") or value)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›outputsçš„å­—ç¬¦ä¸²è¡¨ç¤º
        return str(outputs) if outputs else ""

    def _extract_contexts_from_workflow_outputs(self, outputs: dict[str, Any]) -> list[str]:
        """ä»Workflow APIçš„outputsä¸­æå–ä¸Šä¸‹æ–‡"""
        if not isinstance(outputs, dict):
            return []
        
        contexts = []
        for field in WORKFLOW_API_CONTEXT_FIELDS:
            if field in outputs:
                value = outputs[field]
                if isinstance(value, list):
                    contexts.extend([str(ctx) for ctx in value if ctx])
                elif isinstance(value, str) and value:
                    contexts.append(value)
                break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„å­—æ®µå°±åœæ­¢
        
        return contexts

    def _extract_contexts_from_chat_response(self, data: dict[str, Any]) -> list[str]:
        """ä»Chat APIå“åº”ä¸­æå–retriever_resources"""
        retriever_resources = data.get(CHAT_API_CONTEXT_FIELD, [])
        if not isinstance(retriever_resources, list):
            return []
        
        contexts = []
        for resource in retriever_resources:
            if isinstance(resource, dict):
                # æå–contentå­—æ®µï¼ˆå¦‚æœæœ‰ï¼‰
                content = resource.get("content") or resource.get("chunk_content")
                if content:
                    contexts.append(str(content))
            elif resource:
                contexts.append(str(resource))
        return contexts

    def _log_response_diagnostics(self, data: dict[str, Any], path: str) -> None:
        """è®°å½•APIå“åº”è¯Šæ–­ä¿¡æ¯"""
        logger.debug(f"Dify APIå“åº”å­—æ®µ: {list(data.keys())}")
        
        if self._is_workflow_api(path):
            # Workflow APIè¯Šæ–­ï¼šæ£€æŸ¥data.outputsä¸­çš„ä¸Šä¸‹æ–‡å­—æ®µ
            outputs = data.get("outputs", {})
            if isinstance(outputs, dict):
                for field in WORKFLOW_API_CONTEXT_FIELDS:
                    if field in outputs:
                        contexts_count = len(outputs.get(field, [])) if isinstance(outputs.get(field), list) else 1
                        logger.debug(f"APIå“åº”outputsä¸­åŒ…å«{field}ï¼Œæ•°é‡: {contexts_count}")
                        return
            logger.warning("APIå“åº”outputsä¸­æœªæ‰¾åˆ°retrieved_contextsç›¸å…³å­—æ®µï¼Œå¯èƒ½æ˜¯åº”ç”¨æœªé…ç½®RAG/çŸ¥è¯†åº“æ£€ç´¢")
        else:
            # Chat APIè¯Šæ–­
            if CHAT_API_CONTEXT_FIELD in data:
                resources_count = len(data.get(CHAT_API_CONTEXT_FIELD, []))
                logger.debug(f"APIå“åº”ä¸­åŒ…å«{CHAT_API_CONTEXT_FIELD}ï¼Œæ•°é‡: {resources_count}")
                return
            
            logger.warning(f"APIå“åº”ä¸­æœªæ‰¾åˆ°{CHAT_API_CONTEXT_FIELD}å­—æ®µï¼Œå¯èƒ½æ˜¯åº”ç”¨æœªé…ç½®RAG/çŸ¥è¯†åº“æ£€ç´¢")
            possible_fields = [k for k in data.keys() if "context" in k.lower() or "retriev" in k.lower()]
            if possible_fields:
                logger.debug(f"å‘ç°å¯èƒ½çš„ä¸Šä¸‹æ–‡ç›¸å…³å­—æ®µ: {possible_fields}")

    def _extract_performance_metrics_from_workflow(self, workflow_data: dict[str, Any], total_time: float) -> PerformanceMetrics | None:
        """ä»Workflow APIå“åº”ä¸­æå–æ€§èƒ½æŒ‡æ ‡"""
        # Workflow APIçš„æ€§èƒ½æŒ‡æ ‡åœ¨dataå¯¹è±¡ä¸­
        elapsed_time = workflow_data.get("elapsed_time")
        if elapsed_time is not None:
            total_time = elapsed_time
        
        total_tokens = workflow_data.get("total_tokens", 0)
        
        return PerformanceMetrics(
            total_time=total_time,
            total_tokens=total_tokens,
            input_tokens=0,  # Workflow APIä¸å•ç‹¬æä¾›input/output tokens
            output_tokens=0,
        )

    def _extract_performance_metrics_from_chat(self, data: dict[str, Any], total_time: float) -> PerformanceMetrics | None:
        """ä»Chat APIå“åº”ä¸­æå–æ€§èƒ½æŒ‡æ ‡"""
        if "metadata" not in data:
            return None
        
        meta = data["metadata"]
        usage = meta.get("usage", {})
        performance = PerformanceMetrics(
            total_time=total_time,
            total_tokens=usage.get("total_tokens", 0),
            input_tokens=usage.get("prompt_tokens", 0),
            output_tokens=usage.get("completion_tokens", 0),
        )
        logger.debug(f"æ€§èƒ½æŒ‡æ ‡: tokens={performance.total_tokens}, è¾“å…¥={performance.input_tokens}, è¾“å‡º={performance.output_tokens}")
        return performance

    async def _invoke_streaming(
        self,
        input: str,
        **kwargs: Any,
    ) -> AdapterResponse:
        """æµå¼è°ƒç”¨"""
        if not self._client:
            raise RuntimeError("Adapter must be used as async context manager")

        base_url = self.api_config.get("base_url", "https://api.dify.ai/v1")
        path = kwargs.get("path", "chat-messages")
        url = f"{base_url}/{path}"
        payload = self._build_payload(input, "streaming", **kwargs)
        is_workflow = self._is_workflow_api(path)

        # è·å–è¶…æ—¶æ—¶é—´ï¼šæµå¼å“åº”éœ€è¦æ›´é•¿çš„è¶…æ—¶ï¼ˆåŸºç¡€è¶…æ—¶çš„10å€ï¼Œæœ€å°‘300ç§’ï¼‰
        base_timeout = self.api_config.get("timeout", 30.0)
        streaming_timeout = max(base_timeout * 10, 300.0)

        logger.debug(f"å‘é€æµå¼è¯·æ±‚åˆ°: {url} (APIç±»å‹: {'Workflow' if is_workflow else 'Chat'}), è¶…æ—¶: {streaming_timeout}ç§’")
        start_time = time.time()
        accumulator = StreamingAccumulator()

        async def _read_stream():
            """å†…éƒ¨å‡½æ•°ï¼šè¯»å–æµå¼å“åº”"""
            async with self._client.stream("POST", url, json=payload) as response:
                response.raise_for_status()
                async for line in response.aiter_lines():
                    if not line.strip() or not line.startswith("data: "):
                        continue

                    event_data = line[6:]  # ç§»é™¤ "data: " å‰ç¼€
                    if event_data == "[DONE]":
                        break

                    try:
                        event = json.loads(event_data)
                        current_time = time.time() - start_time
                        if self.show_streaming_content:
                            self._log_streaming_event(event, current_time, is_workflow)
                        accumulator.accumulate(event, current_time)
                        
                        # Chat APIçš„message_endäº‹ä»¶åŒ…å«retriever_resources
                        if not is_workflow and event.get("event") == "message_end":
                            self._extract_contexts_from_message_end(event, accumulator)
                    except json.JSONDecodeError:
                        logger.debug(f"æ— æ³•è§£æSSEè¡Œ: {line[:50]}...")

        # ä½¿ç”¨asyncio.wait_foråŒ…è£…ï¼Œç¡®ä¿æµå¼è¯»å–ä¸ä¼šæ— é™æœŸç­‰å¾…
        try:
            await asyncio.wait_for(_read_stream(), timeout=streaming_timeout)
        except asyncio.TimeoutError:
            elapsed = time.time() - start_time
            logger.warning(f"æµå¼å“åº”è¯»å–è¶…æ—¶ï¼ˆ{streaming_timeout}ç§’ï¼‰ï¼Œå·²è€—æ—¶: {elapsed:.2f}ç§’")
            # å³ä½¿è¶…æ—¶ï¼Œä¹Ÿè¿”å›å·²ç´¯ç§¯çš„æ•°æ®
            if accumulator.answer:
                logger.info(f"è¿”å›å·²ç´¯ç§¯çš„éƒ¨åˆ†å“åº”ï¼ˆ{len(accumulator.answer)}å­—ç¬¦ï¼‰")
            else:
                raise TimeoutError(f"æµå¼å“åº”è¯»å–è¶…æ—¶ï¼Œåœ¨{elapsed:.2f}ç§’å†…æœªæ”¶åˆ°ä»»ä½•æ•°æ®")

        total_time = time.time() - start_time
        logger.debug(f"æµå¼APIè°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {total_time:.3f}ç§’, æ”¶åˆ°tokens: {len(accumulator.token_timestamps)}")
        self._log_streaming_diagnostics(accumulator, path)
        return accumulator.to_adapter_response(start_time)

    def _extract_contexts_from_message_end(self, event: dict[str, Any], accumulator: StreamingAccumulator) -> None:
        """ä»Chat APIçš„message_endäº‹ä»¶ä¸­æå–retriever_resources"""
        metadata = event.get("metadata", {})
        retriever_resources = metadata.get(CHAT_API_CONTEXT_FIELD, [])
        if isinstance(retriever_resources, list):
            for resource in retriever_resources:
                if isinstance(resource, dict):
                    content = resource.get("content") or resource.get("chunk_content")
                    if content and content not in accumulator.contexts:
                        accumulator.contexts.append(str(content))
                elif resource and resource not in accumulator.contexts:
                    accumulator.contexts.append(str(resource))

    def _log_streaming_event(self, event: dict[str, Any], current_time: float, is_workflow: bool) -> None:
        """è®°å½•æµå¼äº‹ä»¶è¯¦æƒ… - ä½¿ç”¨ç­–ç•¥æ¨¡å¼æ¶ˆé™¤if-elifé“¾"""
        event_type = event.get("event", "unknown")
        logger.debug(f"[æµå¼äº‹ä»¶] ç±»å‹: {event_type}, æ—¶é—´: {current_time:.3f}s")
        
        if is_workflow:
            # Workflow APIäº‹ä»¶
            handlers = {
                "workflow_started": self._log_workflow_started_event,
                "node_started": self._log_node_started_event,
                "text_chunk": self._log_text_chunk_event,
                "node_finished": self._log_node_finished_event,
                "workflow_finished": self._log_workflow_finished_event,
            }
        else:
            # Chat APIäº‹ä»¶
            handlers = {
                "message": self._log_message_event,
                "agent_message": self._log_agent_message_event,
                "agent_thought": self._log_agent_thought_event,
                "message_end": self._log_message_end_event,
                "message_file": self._log_message_file_event,
                "error": self._log_error_event,
            }
        
        handler = handlers.get(event_type)
        if handler:
            handler(event)
        elif event_type not in ["ping"]:  # pingäº‹ä»¶ä¸éœ€è¦è®°å½•
            logger.debug(f"[æµå¼äº‹ä»¶] æœªå¤„ç†çš„äº‹ä»¶ç±»å‹: {event_type}")

    def _log_message_event(self, event: dict[str, Any]) -> None:
        """è®°å½•Chat APIçš„messageäº‹ä»¶"""
        answer_chunk = event.get("answer", "")
        if answer_chunk:
            preview = answer_chunk[:100] + ("..." if len(answer_chunk) > 100 else "")
            logger.debug(f"[æµå¼å†…å®¹] ç­”æ¡ˆç‰‡æ®µ: {preview}")

    def _log_agent_message_event(self, event: dict[str, Any]) -> None:
        """è®°å½•Chat APIçš„agent_messageäº‹ä»¶"""
        answer_chunk = event.get("answer", "")
        if answer_chunk:
            preview = answer_chunk[:100] + ("..." if len(answer_chunk) > 100 else "")
            logger.debug(f"[æµå¼å†…å®¹] Agentç­”æ¡ˆç‰‡æ®µ: {preview}")

    def _log_agent_thought_event(self, event: dict[str, Any]) -> None:
        """è®°å½•Chat APIçš„agent_thoughtäº‹ä»¶"""
        thought = event.get("thought", "")
        tool = event.get("tool", "")
        if thought or tool:
            logger.debug(f"[æµå¼æ€è€ƒ] å·¥å…·: {tool}, æ€è€ƒ: {thought[:100] if thought else ''}")

    def _log_message_end_event(self, event: dict[str, Any]) -> None:
        """è®°å½•Chat APIçš„message_endäº‹ä»¶"""
        metadata = event.get("metadata", {})
        usage = metadata.get("usage", {})
        retriever_resources = metadata.get(CHAT_API_CONTEXT_FIELD, [])
        logger.debug(f"[æµå¼å®Œæˆ] æ€»tokens: {usage.get('total_tokens', 0)}, retriever_resourcesæ•°é‡: {len(retriever_resources) if isinstance(retriever_resources, list) else 0}")

    def _log_message_file_event(self, event: dict[str, Any]) -> None:
        """è®°å½•Chat APIçš„message_fileäº‹ä»¶"""
        file_type = event.get("type", "unknown")
        file_id = event.get("id", "unknown")
        logger.debug(f"[æµå¼æ–‡ä»¶] ç±»å‹: {file_type}, ID: {file_id}")

    def _log_error_event(self, event: dict[str, Any]) -> None:
        """è®°å½•Chat APIçš„erroräº‹ä»¶"""
        error_code = event.get("code", "unknown")
        error_message = event.get("message", "")
        logger.warning(f"[æµå¼é”™è¯¯] é”™è¯¯ç : {error_code}, æ¶ˆæ¯: {error_message}")

    def _log_workflow_started_event(self, event: dict[str, Any]) -> None:
        """è®°å½•Workflow APIçš„workflow_startedäº‹ä»¶"""
        data = event.get("data", {})
        workflow_id = data.get("workflow_id", "unknown")
        workflow_run_id = data.get("id", "unknown")
        logger.debug(f"[æµå¼å·¥ä½œæµ] å¼€å§‹æ‰§è¡Œ: workflow_id={workflow_id}, run_id={workflow_run_id}")

    def _log_node_started_event(self, event: dict[str, Any]) -> None:
        """è®°å½•Workflow APIçš„node_startedäº‹ä»¶"""
        data = event.get("data", {})
        node_id = data.get("node_id", "unknown")
        node_type = data.get("node_type", "unknown")
        title = data.get("title", "unknown")
        index = data.get("index", 0)
        logger.debug(f"[æµå¼èŠ‚ç‚¹] å¼€å§‹æ‰§è¡Œ: èŠ‚ç‚¹{index} ({node_id}, ç±»å‹: {node_type}, åç§°: {title})")

    def _log_text_chunk_event(self, event: dict[str, Any]) -> None:
        """è®°å½•text_chunkäº‹ä»¶"""
        data = event.get("data", {})
        text_chunk = data.get("text", "")
        if text_chunk:
            preview = text_chunk[:100] + ("..." if len(text_chunk) > 100 else "")
            logger.debug(f"[æµå¼å†…å®¹] æ–‡æœ¬ç‰‡æ®µ: {preview}")

    def _log_node_finished_event(self, event: dict[str, Any]) -> None:
        """è®°å½•node_finishedäº‹ä»¶"""
        data = event.get("data", {})
        node_id = data.get("node_id", "unknown")
        node_type = data.get("node_type", "unknown")
        outputs = data.get("outputs", {})
        logger.debug(f"[æµå¼èŠ‚ç‚¹] èŠ‚ç‚¹ID: {node_id}, èŠ‚ç‚¹ç±»å‹: {node_type}, è¾“å‡ºå­—æ®µ: {list(outputs.keys())}")
        
        if outputs:
            preview = str(outputs)[:200] + ("..." if len(str(outputs)) > 200 else "")
            logger.debug(f"[æµå¼èŠ‚ç‚¹] è¾“å‡ºå†…å®¹é¢„è§ˆ: {preview}")
        
        self._log_contexts_from_outputs(outputs, f"èŠ‚ç‚¹ {node_id}")

    def _log_workflow_finished_event(self, event: dict[str, Any]) -> None:
        """è®°å½•workflow_finishedäº‹ä»¶"""
        data = event.get("data", {})
        outputs = data.get("outputs", {})
        logger.debug(f"[æµå¼å®Œæˆ] æ€»tokens: {data.get('total_tokens', 0)}, è€—æ—¶: {data.get('elapsed_time', 0):.3f}s")
        logger.debug(f"[æµå¼å®Œæˆ] æœ€ç»ˆoutputså­—æ®µ: {list(outputs.keys()) if isinstance(outputs, dict) else 'N/A'}")
        
        if isinstance(outputs, dict):
            self._log_contexts_from_outputs(outputs, "workflow_finished")

    def _log_contexts_from_outputs(self, outputs: dict[str, Any], source: str) -> None:
        """ä»outputsä¸­æŸ¥æ‰¾å¹¶è®°å½•contextså­—æ®µï¼ˆWorkflow APIï¼‰"""
        if not isinstance(outputs, dict):
            return
        
        for key in WORKFLOW_API_CONTEXT_FIELDS:
            if key not in outputs:
                continue
            
            contexts = outputs[key]
            count = len(contexts) if isinstance(contexts, list) else 1
            logger.info(f"[æµå¼ä¸Šä¸‹æ–‡] âœ… ä»{source}çš„ {key} å­—æ®µæå–åˆ° {count} ä¸ªä¸Šä¸‹æ–‡")
            
            if isinstance(contexts, list) and len(contexts) > 0:
                preview = str(contexts[0])[:100] + ("..." if len(str(contexts[0])) > 100 else "")
                logger.debug(f"[æµå¼ä¸Šä¸‹æ–‡] ç¬¬ä¸€ä¸ªä¸Šä¸‹æ–‡é¢„è§ˆ: {preview}")
            break

    def _log_streaming_diagnostics(self, accumulator: StreamingAccumulator, path: str) -> None:
        """è®°å½•æµå¼å“åº”è¯Šæ–­ä¿¡æ¯"""
        is_workflow = self._is_workflow_api(path)
        
        if accumulator.contexts:
            field_name = "retrieved_contexts" if is_workflow else CHAT_API_CONTEXT_FIELD
            logger.info(f"âœ… æµå¼æ¨¡å¼æˆåŠŸæå–åˆ° {len(accumulator.contexts)} ä¸ª{field_name}")
            for i, ctx in enumerate(accumulator.contexts[:2], 1):
                preview = ctx[:100] + ("..." if len(ctx) > 100 else ctx)
                logger.debug(f"   ä¸Šä¸‹æ–‡{i}é¢„è§ˆ: {preview}")
            return
        
        if is_workflow:
            logger.warning("âš ï¸ æµå¼æ¨¡å¼retrieved_contextsä¸ºç©ºï¼Œå¯èƒ½æ˜¯èŠ‚ç‚¹è¾“å‡ºä¸­æœªåŒ…å«retrieved_contextså­—æ®µ")
            if "nodes" not in accumulator.metadata:
                logger.warning("   metadataä¸­æœªæ‰¾åˆ°nodeså­—æ®µï¼Œæ— æ³•è¿›ä¸€æ­¥è¯Šæ–­")
                return
            self._diagnose_missing_contexts(accumulator.metadata)
        else:
            logger.warning(f"âš ï¸ æµå¼æ¨¡å¼{CHAT_API_CONTEXT_FIELD}ä¸ºç©ºï¼Œå¯èƒ½æ˜¯åº”ç”¨æœªé…ç½®RAG/çŸ¥è¯†åº“æ£€ç´¢ï¼Œæˆ–message_endäº‹ä»¶ä¸­æœªåŒ…å«è¯¥å­—æ®µ")

    def _diagnose_missing_contexts(self, metadata: dict[str, Any]) -> None:
        """è¯Šæ–­ç¼ºå¤±çš„contextså­—æ®µ"""
        nodes = metadata.get("nodes", [])
        logger.warning(f"   æµå¼å“åº”åŒ…å« {len(nodes)} ä¸ªèŠ‚ç‚¹ï¼Œæ£€æŸ¥èŠ‚ç‚¹è¾“å‡º...")
        
        found_contexts = False
        for i, node in enumerate(nodes, 1):
            node_id = node.get("node_id", f"èŠ‚ç‚¹{i}")
            node_type = node.get("node_type", "unknown")
            outputs = node.get("outputs", {})
            logger.warning(f"   èŠ‚ç‚¹{i} ({node_id}, ç±»å‹: {node_type}) è¾“å‡ºå­—æ®µ: {list(outputs.keys()) if isinstance(outputs, dict) else 'N/A'}")
            
            if isinstance(outputs, dict):
                found_contexts = self._check_outputs_for_contexts(outputs, f"èŠ‚ç‚¹{i}") or found_contexts
        
        workflow_outputs = metadata.get("outputs", {})
        if isinstance(workflow_outputs, dict):
            logger.warning(f"   workflow_finishedçš„outputså­—æ®µ: {list(workflow_outputs.keys())}")
            found_contexts = self._check_outputs_for_contexts(workflow_outputs, "workflow_finished") or found_contexts
        
        if not found_contexts:
            logger.warning("   ğŸ’¡ æ‰€æœ‰èŠ‚ç‚¹è¾“å‡ºå’Œworkflow_finishedä¸­å‡æœªæ‰¾åˆ°retrieved_contextsç›¸å…³å­—æ®µ")
            logger.warning("   ğŸ’¡ å¯èƒ½åŸå› ï¼š")
            logger.warning("      1. æ™ºèƒ½ä½“æœªé…ç½®RAG/çŸ¥è¯†åº“æ£€ç´¢åŠŸèƒ½")
            logger.warning("      2. å½“å‰æŸ¥è¯¢æœªè§¦å‘çŸ¥è¯†åº“æ£€ç´¢")
            logger.warning("      3. Dify APIå“åº”æ ¼å¼ä¸é¢„æœŸä¸ç¬¦ï¼ˆå»ºè®®æ£€æŸ¥show_streaming_contentæ—¥å¿—ï¼‰")

    def _check_outputs_for_contexts(self, outputs: dict[str, Any], source: str) -> bool:
        """æ£€æŸ¥outputsä¸­æ˜¯å¦æœ‰contextså­—æ®µï¼ˆWorkflow APIï¼‰ï¼Œè¿”å›æ˜¯å¦æ‰¾åˆ°"""
        found = False
        for key in WORKFLOW_API_CONTEXT_FIELDS:
            if key not in outputs:
                continue
            
            found = True
            value = outputs[key]
            logger.warning(f"     âš ï¸ {source}ä¸­å‘ç°å­—æ®µ {key}ï¼Œä½†å€¼ä¸º: {type(value).__name__}")
            
            if isinstance(value, list):
                logger.warning(f"       åˆ—è¡¨é•¿åº¦: {len(value)}")
                if len(value) > 0:
                    logger.warning(f"       ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹: {type(value[0]).__name__}")
                    preview = str(value[0])[:100] + ("..." if len(str(value[0])) > 100 else "")
                    logger.warning(f"       ç¬¬ä¸€ä¸ªå…ƒç´ é¢„è§ˆ: {preview}")
            elif isinstance(value, str):
                logger.warning(f"       å­—ç¬¦ä¸²é•¿åº¦: {len(value)}")
                preview = value[:100] + ("..." if len(value) > 100 else "")
                logger.warning(f"       å­—ç¬¦ä¸²é¢„è§ˆ: {preview}")
            break
        
        # æ£€æŸ¥åµŒå¥—å­—å…¸
        for key, value in outputs.items():
            if isinstance(value, dict):
                logger.debug(f"     å­—æ®µ {key} æ˜¯åµŒå¥—å­—å…¸ï¼ŒåŒ…å«: {list(value.keys())}")
                if "retrieved_contexts" in value:
                    logger.warning(f"     âš ï¸ åœ¨åµŒå¥—å­—æ®µ {key}.retrieved_contexts ä¸­å‘ç°ä¸Šä¸‹æ–‡")
                
        return found